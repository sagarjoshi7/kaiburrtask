{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Text classification (multiclass) \n\n### Tutorial for beginners in text classification analysis using Python","metadata":{}},{"cell_type":"markdown","source":"<a id='imp'></a>\n## Importing packages and loading data","metadata":{}},{"cell_type":"code","source":"# Input data files are available in the \"../input/\" directory.\nimport os\nprint(os.listdir(\"../input\"))\n\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import randint\nimport seaborn as sns # used for plot interactive graph. \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom io import StringIO\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_selection import chi2\nfrom IPython.display import display\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\n#import warnings\n#warnings.filterwarnings(\"ignore\", category=FutureWarning)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-01T06:44:54.841843Z","iopub.execute_input":"2021-12-01T06:44:54.842458Z","iopub.status.idle":"2021-12-01T06:44:55.969918Z","shell.execute_reply.started":"2021-12-01T06:44:54.842119Z","shell.execute_reply":"2021-12-01T06:44:55.968709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading data\ndf = pd.read_csv('../input/rows.csv')\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:44:55.971285Z","iopub.execute_input":"2021-12-01T06:44:55.971629Z","iopub.status.idle":"2021-12-01T06:45:13.018000Z","shell.execute_reply.started":"2021-12-01T06:44:55.971562Z","shell.execute_reply":"2021-12-01T06:45:13.017204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='eda'></a>\n## Exploratory Data Analysis (EDA) and Feature Engineering","metadata":{}},{"cell_type":"code","source":"df.head(2).T # Columns are shown in rows for easy reading","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:45:13.019419Z","iopub.execute_input":"2021-12-01T06:45:13.019752Z","iopub.status.idle":"2021-12-01T06:45:13.049923Z","shell.execute_reply.started":"2021-12-01T06:45:13.019689Z","shell.execute_reply":"2021-12-01T06:45:13.049170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The dataset contains features that are not necessary to solve our multi-classification problem. For this text classification problem, we are going to build another dataframe that contains ‘Product’ and ‘Consumer complaint narrative’ (renamed as 'Consumer_complaint').","metadata":{}},{"cell_type":"code","source":"# Create a new dataframe with two columns\ndf1 = df[['Product', 'Consumer complaint narrative']].copy()\n\n# Remove missing values (NaN)\ndf1 = df1[pd.notnull(df1['Consumer complaint narrative'])]\n\n# Renaming second column for a simpler name\ndf1.columns = ['Product', 'Consumer_complaint'] \n\ndf1.shape","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-12-01T06:46:07.908927Z","iopub.execute_input":"2021-12-01T06:46:07.909499Z","iopub.status.idle":"2021-12-01T06:46:08.134748Z","shell.execute_reply.started":"2021-12-01T06:46:07.909454Z","shell.execute_reply":"2021-12-01T06:46:08.133965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Percentage of complaints with text\ntotal = df1['Consumer_complaint'].notnull().sum()\nround((total/len(df)*100),1)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:46:09.133491Z","iopub.execute_input":"2021-12-01T06:46:09.133822Z","iopub.status.idle":"2021-12-01T06:46:09.203260Z","shell.execute_reply.started":"2021-12-01T06:46:09.133761Z","shell.execute_reply":"2021-12-01T06:46:09.202475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From more than 1 million complaints, there are about 380,000 cases with text (~ 30% of the original dataset is not null). This is still a good number to work with. Now let's have a look at the categories we want to classify each complaint.","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(df.Product.unique()).values","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:46:15.490698Z","iopub.execute_input":"2021-12-01T06:46:15.491320Z","iopub.status.idle":"2021-12-01T06:46:15.603943Z","shell.execute_reply.started":"2021-12-01T06:46:15.491275Z","shell.execute_reply":"2021-12-01T06:46:15.602940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 18 different classes or categories (target). However; it is observed that some classes are contained in others. For instance, ‘Credit card’ and ‘Prepaid card’ are contained in ‘Credit card or prepaid card’ category. Now, imagine there is a new complaint about Credit card and we want to classify it. The algorithm can either classify this complaint as 'Credit card' or 'Credit card or prepaid' and it would be correct. Nevertheless, this would affect model performance. In order to avoid this problem, the names of some categories were renamed.","metadata":{}},{"cell_type":"code","source":"# Because the computation is time consuming (in terms of CPU), the data was sampled\ndf2 = df1.sample(10000, random_state=1).copy()","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:46:21.035201Z","iopub.execute_input":"2021-12-01T06:46:21.035805Z","iopub.status.idle":"2021-12-01T06:46:21.056410Z","shell.execute_reply.started":"2021-12-01T06:46:21.035456Z","shell.execute_reply":"2021-12-01T06:46:21.055652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Renaming categories\ndf2.replace({'Product': \n             {'Credit reporting, credit repair services, or other personal consumer reports': \n              'Credit reporting, repair, or other', \n              'Credit reporting': 'Credit reporting, repair, or other',\n             'Credit card': 'Credit card or prepaid card',\n             'Prepaid card': 'Credit card or prepaid card',\n             'Payday loan': 'Payday loan, title loan, or personal loan',\n             'Money transfer': 'Money transfer, virtual currency, or money service',\n             'Virtual currency': 'Money transfer, virtual currency, or money service'}}, \n            inplace= True)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:46:21.869976Z","iopub.execute_input":"2021-12-01T06:46:21.870551Z","iopub.status.idle":"2021-12-01T06:46:21.885900Z","shell.execute_reply.started":"2021-12-01T06:46:21.870501Z","shell.execute_reply":"2021-12-01T06:46:21.884791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(df2.Product.unique())","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:46:29.497612Z","iopub.execute_input":"2021-12-01T06:46:29.497929Z","iopub.status.idle":"2021-12-01T06:46:29.512582Z","shell.execute_reply.started":"2021-12-01T06:46:29.497872Z","shell.execute_reply":"2021-12-01T06:46:29.511738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The number of classes were reduced from 18 to 13. <br><br>Now we need to represent each class as a number, so as our predictive model can better understand the different categories.","metadata":{}},{"cell_type":"code","source":"# Create a new column 'category_id' with encoded categories \ndf2['category_id'] = df2['Product'].factorize()[0]\ncategory_id_df = df2[['Product', 'category_id']].drop_duplicates()\n\n\n# Dictionaries for future use\ncategory_to_id = dict(category_id_df.values)\nid_to_category = dict(category_id_df[['category_id', 'Product']].values)\n\n# New dataframe\ndf2.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:46:37.603760Z","iopub.execute_input":"2021-12-01T06:46:37.604333Z","iopub.status.idle":"2021-12-01T06:46:37.629069Z","shell.execute_reply.started":"2021-12-01T06:46:37.604009Z","shell.execute_reply":"2021-12-01T06:46:37.628493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(8,6))\ncolors = ['grey','grey','grey','grey','grey','grey','grey','grey','grey',\n    'grey','darkblue','darkblue','darkblue']\ndf2.groupby('Product').Consumer_complaint.count().sort_values().plot.barh(\n    ylim=0, color=colors, title= 'NUMBER OF COMPLAINTS IN EACH PRODUCT CATEGORY\\n')\nplt.xlabel('Number of ocurrences', fontsize = 10);","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:46:41.531354Z","iopub.execute_input":"2021-12-01T06:46:41.531977Z","iopub.status.idle":"2021-12-01T06:46:42.031291Z","shell.execute_reply.started":"2021-12-01T06:46:41.531924Z","shell.execute_reply":"2021-12-01T06:46:42.030519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5,\n                        ngram_range=(1, 2), \n                        stop_words='english')\n\n# We transform each complaint into a vector\nfeatures = tfidf.fit_transform(df2.Consumer_complaint).toarray()\n\nlabels = df2.category_id\n\nprint(\"Each of the %d complaints is represented by %d features (TF-IDF score of unigrams and bigrams)\" %(features.shape))","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:46:46.867697Z","iopub.execute_input":"2021-12-01T06:46:46.868250Z","iopub.status.idle":"2021-12-01T06:46:53.647057Z","shell.execute_reply.started":"2021-12-01T06:46:46.868203Z","shell.execute_reply":"2021-12-01T06:46:53.646269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finding the three most correlated terms with each of the product categories\nN = 3\nfor Product, category_id in sorted(category_to_id.items()):\n  features_chi2 = chi2(features, labels == category_id)\n  indices = np.argsort(features_chi2[0])\n  feature_names = np.array(tfidf.get_feature_names())[indices]\n  unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n  bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n  print(\"\\n==> %s:\" %(Product))\n  print(\"  * Most Correlated Unigrams are: %s\" %(', '.join(unigrams[-N:])))\n  print(\"  * Most Correlated Bigrams are: %s\" %(', '.join(bigrams[-N:])))","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:46:53.648419Z","iopub.execute_input":"2021-12-01T06:46:53.648642Z","iopub.status.idle":"2021-12-01T06:47:08.582298Z","shell.execute_reply.started":"2021-12-01T06:46:53.648603Z","shell.execute_reply":"2021-12-01T06:47:08.581332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='sp'></a>\n### Spliting the data into train and test sets\nThe original data was divided into features (X) and target (y), which were then splitted into train (75%) and test (25%) sets. Thus, the algorithms would be trained on one set of data and tested out on a completely different set of data (not seen before by the algorithm).","metadata":{}},{"cell_type":"code","source":"X = df2['Consumer_complaint'] # Collection of documents\ny = df2['Product'] # Target or the labels we want to predict (i.e., the 13 different complaints of products)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.25,\n                                                    random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:47:20.078938Z","iopub.execute_input":"2021-12-01T06:47:20.079228Z","iopub.status.idle":"2021-12-01T06:47:20.088398Z","shell.execute_reply.started":"2021-12-01T06:47:20.079182Z","shell.execute_reply":"2021-12-01T06:47:20.087448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='m'></a>\n### Models","metadata":{}},{"cell_type":"code","source":"models = [\n    RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0),\n    LinearSVC(),\n    MultinomialNB(),\n    LogisticRegression(random_state=0),\n]\n\n# 5 Cross-validation\nCV = 5\ncv_df = pd.DataFrame(index=range(CV * len(models)))\n\nentries = []\nfor model in models:\n  model_name = model.__class__.__name__\n  accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n  for fold_idx, accuracy in enumerate(accuracies):\n    entries.append((model_name, fold_idx, accuracy))\n    \ncv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:47:26.950439Z","iopub.execute_input":"2021-12-01T06:47:26.950727Z","iopub.status.idle":"2021-12-01T06:49:17.969145Z","shell.execute_reply.started":"2021-12-01T06:47:26.950677Z","shell.execute_reply":"2021-12-01T06:49:17.968261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='sum'></a>\n## Comparison of model performance\n\nThe best mean acuracy was obtained with LinearSVC.","metadata":{}},{"cell_type":"code","source":"mean_accuracy = cv_df.groupby('model_name').accuracy.mean()\nstd_accuracy = cv_df.groupby('model_name').accuracy.std()\n\nacc = pd.concat([mean_accuracy, std_accuracy], axis= 1, \n          ignore_index=True)\nacc.columns = ['Mean Accuracy', 'Standard deviation']\nacc","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:50:58.831855Z","iopub.execute_input":"2021-12-01T06:50:58.832194Z","iopub.status.idle":"2021-12-01T06:50:58.852692Z","shell.execute_reply.started":"2021-12-01T06:50:58.832154Z","shell.execute_reply":"2021-12-01T06:50:58.851886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,5))\nsns.boxplot(x='model_name', y='accuracy', \n            data=cv_df, \n            color='lightblue', \n            showmeans=True)\nplt.title(\"MEAN ACCURACY (cv = 5)\\n\", size=14);","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:51:04.858771Z","iopub.execute_input":"2021-12-01T06:51:04.859070Z","iopub.status.idle":"2021-12-01T06:51:05.131265Z","shell.execute_reply.started":"2021-12-01T06:51:04.859026Z","shell.execute_reply":"2021-12-01T06:51:05.130471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='ev'></a>\n## Model Evaluation","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test,indices_train,indices_test = train_test_split(features, \n                                                               labels, \n                                                               df2.index, test_size=0.25, \n                                                               random_state=1)\nmodel = LinearSVC()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:51:10.272596Z","iopub.execute_input":"2021-12-01T06:51:10.273144Z","iopub.status.idle":"2021-12-01T06:51:13.052548Z","shell.execute_reply.started":"2021-12-01T06:51:10.273101Z","shell.execute_reply":"2021-12-01T06:51:13.051149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='m'></a>\n### Precision, Recall, F1-score","metadata":{}},{"cell_type":"code","source":"# Classification report\nprint('\\t\\t\\t\\tCLASSIFICATIION METRICS\\n')\nprint(metrics.classification_report(y_test, y_pred, \n                                    target_names= df2['Product'].unique()))","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:51:19.267131Z","iopub.execute_input":"2021-12-01T06:51:19.267455Z","iopub.status.idle":"2021-12-01T06:51:19.286626Z","shell.execute_reply.started":"2021-12-01T06:51:19.267377Z","shell.execute_reply":"2021-12-01T06:51:19.285688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='cm'></a>\n### Confusion Matrix\n\nA Confusion Matrix is a table which rows represent the actual class and columns represents the predicted class.<br><br>\nIf we had a perfect model that always classifies correctly a new complaint, then the confusion matrix would have values in the diagonal only (where predicted label = actual label).","metadata":{}},{"cell_type":"code","source":"conf_mat = confusion_matrix(y_test, y_pred)\nfig, ax = plt.subplots(figsize=(8,8))\nsns.heatmap(conf_mat, annot=True, cmap=\"Blues\", fmt='d',\n            xticklabels=category_id_df.Product.values, \n            yticklabels=category_id_df.Product.values)\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.title(\"CONFUSION MATRIX - LinearSVC\\n\", size=16);","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:51:38.362860Z","iopub.execute_input":"2021-12-01T06:51:38.363344Z","iopub.status.idle":"2021-12-01T06:51:40.107255Z","shell.execute_reply.started":"2021-12-01T06:51:38.363305Z","shell.execute_reply":"2021-12-01T06:51:40.106513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In general, the confusion matrix looks good (clear diagonal that represents correct classifications). Nevertheless, there are cases were the complaint was classified in a wrong class.\n\n#### Misclassified complaints\nLet’s have a look at the cases that were wrongly classified.","metadata":{}},{"cell_type":"code","source":"for predicted in category_id_df.category_id:\n  for actual in category_id_df.category_id:\n    if predicted != actual and conf_mat[actual, predicted] >= 20:\n      print(\"'{}' predicted as '{}' : {} examples.\".format(id_to_category[actual], \n                                                           id_to_category[predicted], \n                                                           conf_mat[actual, predicted]))\n    \n      display(df2.loc[indices_test[(y_test == actual) & (y_pred == predicted)]][['Product', \n                                                                'Consumer_complaint']])\n      print('')","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:51:47.028806Z","iopub.execute_input":"2021-12-01T06:51:47.029095Z","iopub.status.idle":"2021-12-01T06:51:47.153458Z","shell.execute_reply.started":"2021-12-01T06:51:47.029049Z","shell.execute_reply":"2021-12-01T06:51:47.151968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Most correlated terms with each category","metadata":{}},{"cell_type":"code","source":"model.fit(features, labels)\n\nN = 4\nfor Product, category_id in sorted(category_to_id.items()):\n  indices = np.argsort(model.coef_[category_id])\n  feature_names = np.array(tfidf.get_feature_names())[indices]\n  unigrams = [v for v in reversed(feature_names) if len(v.split(' ')) == 1][:N]\n  bigrams = [v for v in reversed(feature_names) if len(v.split(' ')) == 2][:N]\n  print(\"\\n==> '{}':\".format(Product))\n  print(\"  * Top unigrams: %s\" %(', '.join(unigrams)))\n  print(\"  * Top bigrams: %s\" %(', '.join(bigrams)))","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:52:06.612260Z","iopub.execute_input":"2021-12-01T06:52:06.612914Z","iopub.status.idle":"2021-12-01T06:52:09.520758Z","shell.execute_reply.started":"2021-12-01T06:52:06.612853Z","shell.execute_reply":"2021-12-01T06:52:09.519874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='pred'></a>\n## Predictions\n\nNow let's make a few predictions on unseen data.<br>","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.25,\n                                                    random_state = 0)\n\ntfidf = TfidfVectorizer(sublinear_tf=True, min_df=5,\n                        ngram_range=(1, 2), \n                        stop_words='english')\n\nfitted_vectorizer = tfidf.fit(X_train)\ntfidf_vectorizer_vectors = fitted_vectorizer.transform(X_train)\n\nmodel = LinearSVC().fit(tfidf_vectorizer_vectors, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:52:18.098020Z","iopub.execute_input":"2021-12-01T06:52:18.098330Z","iopub.status.idle":"2021-12-01T06:52:25.372626Z","shell.execute_reply.started":"2021-12-01T06:52:18.098276Z","shell.execute_reply":"2021-12-01T06:52:25.371596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see what is the classification that our model gives to this new complaint.","metadata":{}},{"cell_type":"code","source":"new_complaint = \"\"\"I have been enrolled back at XXXX XXXX University in the XX/XX/XXXX. Recently, i have been harassed by \\\nNavient for the last month. I have faxed in paperwork providing them with everything they needed. And yet I am still getting \\\nphone calls for payments. Furthermore, Navient is now reporting to the credit bureaus that I am late. At this point, \\\nNavient needs to get their act together to avoid me taking further action. I have been enrolled the entire time and my \\\ndeferment should be valid with my planned graduation date being the XX/XX/XXXX.\"\"\"\nprint(model.predict(fitted_vectorizer.transform([new_complaint])))","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:52:26.450127Z","iopub.execute_input":"2021-12-01T06:52:26.450465Z","iopub.status.idle":"2021-12-01T06:52:26.459957Z","shell.execute_reply.started":"2021-12-01T06:52:26.450406Z","shell.execute_reply":"2021-12-01T06:52:26.458850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The algorithm has classified this text as a \"Student loan\" complaint. Now let's look at the real label of this complaint.","metadata":{}},{"cell_type":"code","source":"df2[df2['Consumer_complaint'] == new_complaint]","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:52:32.767800Z","iopub.execute_input":"2021-12-01T06:52:32.768129Z","iopub.status.idle":"2021-12-01T06:52:32.791720Z","shell.execute_reply.started":"2021-12-01T06:52:32.768062Z","shell.execute_reply":"2021-12-01T06:52:32.790721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our model was correct, the complaint was about **Student Loan**. Note that this customer has used terms with high TFIDF score, such us **Navient[](http://)**.<br><br>\nLet's check another example.","metadata":{}},{"cell_type":"code","source":"new_complaint_2 = \"\"\"Equifax exposed my personal information without my consent, as part of their recent data breach. \\\nIn addition, they dragged their feet in the announcement of the report, and even allowed their upper management to sell \\\noff stock before the announcement.\"\"\"\nprint(model.predict(fitted_vectorizer.transform([new_complaint_2])))","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:52:35.939016Z","iopub.execute_input":"2021-12-01T06:52:35.939736Z","iopub.status.idle":"2021-12-01T06:52:35.946852Z","shell.execute_reply.started":"2021-12-01T06:52:35.939345Z","shell.execute_reply":"2021-12-01T06:52:35.945715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2[df2['Consumer_complaint'] == new_complaint_2]","metadata":{"execution":{"iopub.status.busy":"2021-12-01T06:52:41.228153Z","iopub.execute_input":"2021-12-01T06:52:41.228435Z","iopub.status.idle":"2021-12-01T06:52:41.248723Z","shell.execute_reply.started":"2021-12-01T06:52:41.228383Z","shell.execute_reply":"2021-12-01T06:52:41.247672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}